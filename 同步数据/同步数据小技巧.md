### 同步数据过多问题
```shell
由于手动同步全量代码会出现程序被killed问题。

原因如下：
1.一次获取太多数据同步
	处理方法：
	- 可分批获取，按照时间或者主要字段的范围获取，避免一次取过多数据
	- 一批获取数据太多，可优化query查询语句，减少不必要同步的数据
2.内部程序需要处理的数据过多
	优化内部程序：
	- 不要一次处理过多数据，进行分批处理
```

1. 减少不必要数据方法
	- 使用group by或者distinct去重
	
	  ```mysql
	  select ad_creative_id, ad_id, area, dt, position, platform, format, media, appid, channel from mt.ad_log where ad_id > 118559000 and ad_id <= 118569000 and dt between '2021-03-23' and '2021-04-23' group by ad_creative_id, ad_id,area, dt, position, platform, format, media, appid, channel
	  
	  2323 rows 0 seconds runtime
	  Updated just now
	  ```
	
	  
	
	- 只取需要同步的字段
	
	  ```mysql
	  select ad_creative_id, ad_id from mt.ad_log where ad_id > 118559000 and ad_id <= 118569000  and dt between '2021-04-24' and '2021-04-28' group by ad_creative_id, ad_id
	  
	  194 rows 0 seconds runtime
	  Updated just now
	  ```
	
	  
	
	- 不能只取个别字段同步，但是只需要特定字段
	
	  ```mysql
	  select ad_creative_id, ad_id, max(area), max(dt), max(position), max(platform), max(format), max(media), max(appid), max(channel) from mt.ad_log where ad_id > 118559000 and ad_id <= 118569000 and dt between '2021-03-23' and '2021-04-23' group by ad_creative_id, ad_id
	  
	  194 rows 0 seconds runtime
	  Updated just now
	  
	  ```
	
	  
	
2. 增加内存

   ![image-20210429171236489](/home/youmi/.config/Typora/typora-user-images/image-20210429171236489.png)

3. 代码内部优化

   - 使用python流式游标

   - 一次查询过多数据的sql使用分页查询

     1. `query_page( query: str, last_id=0, no_rows_sleep_interval=0)` 分页查询

        ```python
        '''
        分页查询数据, 直到没有数据返回, 避免一次性返回太多数据
        query 里面需要有个 %s 占位, e.g.: select * from ad where id > %s and id > 1024
        如果是返回字典的，按照_last_id列分页
        '''
        
            for row in d.query_page("select ad_id, ad_id, ext from ad_ext where ad_id > %s limit 3"):
                logging.debug(row)
        ```

        

     2. chop()  批量返回

        ``` python
        def chop(iterable: Iterable, batch=500) -> Generator:
            """迭代器按照指定大小批量返回列表"""
            piece = []
            for ele in iterable:
                piece.append(ele)
                if len(piece) >= batch:
                    yield piece
                    piece = []
            if piece:
                yield piece
        ```

        
## 同步脚本启动方式



- 手动跑脚本

  1. 在rancher创建手动跑脚本的APP

  2. 用screen管理窗口，防止rancher退出后，关闭同步进程

     ```shell
     apt-get update && apt-get install vim -y && apt-get install screen -y && apt-get install less -y
     
     screen -S job -s bash（创建job的会话）
     ```

     

  3. 手动同步命令(全量同步)

     - 若ad_id是主键且唯一，则使用_last_id进行分页查询并同步

     ```shell
     python manage.py es_sync_ad_product 
     --max_flush_cnt=1000 
     --db_dsn=alishh.ag-db-40.adData 
     --query="select ad_id as _last_id, ad_id, product_id, 'adData.ad_product' as __table from ad_product  where ad_id > %s limit 3000"
     ```

     - 若没有唯一主键，则使用query-dims。通过batch_size，取每次查询的范围，分批查询并同步。

     ```mysql
     # 分批查询,通过between 0,0+batch_size获取,不需要limit
     select * from table where id between start, end+batch_size
     ```

     ```shell
     """
     1.db_dim：指定获取batch_size的数据源
     2.querydims：获取batch_size的query
     3.db_dsn:目标查询数据源
     4.query:目标查询数据语句
     """
     python manage.py ch_sync_river 
     --db_dsn=alishh.ag-db-10.ecData_v3 
     --query="select product_id, category_id from product_category_relation where product_id > {start_id} and product_id <= {end_id}" 
     --max_flush_cnt=100000 
     --querydims="select arrayJoin(range(toUInt32(ceil((49840377) / 100000)))) as round, round * 100000 as start_id, (round + 1) * 100000 as end_id " 
     --db_dim="clickhouse://ec-00.ag.alishh:9000/mt"
     
     
     ```

     

  4. 恢复会话

     ```shell
     # 查看所有会话
     screen -ls
     
     # 回到指定会话
     screen -d -r yourname
     （attached）状态会话 -> 结束当前session并回到yourname这个session
     ```

     

- 自动跑脚本

  ##### 跑全量数据前，先把正式脚本的消费占位，防止数据丢失

  1. 登陆对应kafka机器

     `ssh -p36000 kafka-00.ag.alishh`

     `cd bin/kakfa`

  2. 消费kafka的一个数据作为新的kafka组别消费的开端
  
     可以在`https://kafka-manager-alishh.umlife.net/` 查看
  
     - bootstrap-server地址
  
     - 脚本监控的topic
  
     - kafka消费的组别
  
     ```shell
      ./bin/kafka-console-consumer.sh --bootstrap-server 172.19.33.10:9092 --topic binlog-ag-db-41-addata-正式脚本的监控topic --max-messages 1  --consumer-property group.id=正式脚本的组
     ```
  
  3. 部署正式跑脚本服务
  
     如果部署cmd时，不设置指定的kafka_group，那么kafka_group则默认时与dj命令一样。

为什么要占位？

1. 当从测试组消费切换到正式组消费过程中，如果是先重跑全量正式数据再跑正式脚本增量同步，这个过程中会出现数据丢失，因此需要占位。

2. kafka组别问题：

   如果消费是同一个kafka组别，可以不需要占位，因为不会丢失数据。



